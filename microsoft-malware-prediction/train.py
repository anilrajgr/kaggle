import pandas as pd
import glob
import shutil
import sys
import numpy as np
from IPython.display import display, HTML
import matplotlib.pyplot as plt
import math
from time import time
from sklearn.impute import SimpleImputer
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import fbeta_score
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
import pickle
from scipy.special import boxcox1p
import os

def include(filename):
    if os.path.exists(filename):
        execfile(filename)

def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): 
    '''
    inputs:
       - learner: the learning algorithm to be trained and predicted on
       - sample_size: the size of samples (number) to be drawn from training set
       - X_train: features training set
       - y_train: income training set
       - X_test: features testing set
       - y_test: income testing set
    '''
    
    results = {}
    
    # TODO: Fit the learner to the training data using slicing with 'sample_size'
    start = time() # Get start time
    learner.fit(X_train[:sample_size], y_train[:sample_size])
    end = time() # Get end time
    
    # TODO: Calculate the training time
    results['train_time'] = end - start
        
    # TODO: Get the predictions on the test set,
    #       then get predictions on the first 300 training samples
    start = time() # Get start time
    predictions_test = learner.predict(X_test)
    predictions_train = learner.predict(X_train)
    end = time() # Get end time
       
    # TODO: Calculate the total prediction time
    results['pred_time'] = end - start
            
    # TODO: Compute accuracy on the first 300 training samples
    results['acc_train'] = accuracy_score(y_train, learner.predict(X_train))
        
    # TODO: Compute accuracy on test set
    results['acc_test'] = accuracy_score(y_test, learner.predict(X_test))
    
    # TODO: Compute F-score on the the first 300 training samples
    results['f_train'] = fbeta_score(y_train, learner.predict(X_train), beta=0.5)
        
    # TODO: Compute F-score on the test set
    results['f_test'] = fbeta_score(y_test, learner.predict(X_test), beta=0.5)
       
    # Success
    print("{} trained on {} samples.".format(learner.__class__.__name__, sample_size))
    print(results)
        
    # Return the results
    return learner

def break_and_get_part(value, position):
    return value.split(".")[position]

def break_and_get_part_osbuildlab(value, position):
    if position < 4:
        try:
            return value.split(".")[position]
        except:
            return math.nan
    elif position == 4:
        try:
            return value.split(".")[4].split('-')[0]
        except:
            return math.nan
    elif position == 5:
        try:
            return value.split(".")[4].split('-')[1]
        except:
            return math.nan

include('process_df.py')

file = 'data/train.csv'
df = pd.read_csv(file)

df = process_df(df)
drop_list2 = ['MachineIdentifier']
df.drop(drop_list2, axis=1, inplace=True)

# Split the data in features and target label
labels = df['HasDetections']
features = df.drop('HasDetections', axis=1)

labels.to_pickle('labels.pkl')
features.to_pickle('labels.pkl')

X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 0)

# clf = GaussianNB()
clf = XGBClassifier()

trained_model = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)
with open('trained_model.pkl', 'wb') as f:
    pickle.dump(clf, f)
