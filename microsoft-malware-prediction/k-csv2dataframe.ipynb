{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(copy=False, fill_value=None, strategy='most_frequent', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'lion' 'li-i' '#' 'lip' 'liio' 'vbox' 'li p' 'real' 'unkn' 'pbac'\n",
      " 'li' 'bq20' 'nimh' '\\x04lio' 'lgi0' 'lhp0' 'ithi' 'batt' 'lipp' 'lipo'\n",
      " '4cel' 'ram' 'lit' 'a140' 'bad' 'asmb' 'virt' 'ca48' '4ion' 'd' 'a132'\n",
      " 'ÿÿÿÿ' 'cl53' 'lio' 'li-l' '÷ÿóö' 'í\\x03-i' '0x0b' 'lgs0' '3ion' 'ots0'\n",
      " 'lai0' 'lilo' 'pa50' 'h4°s' '5nm1' 'li-p' 'lhpo' '0ts0' 'pad0' 'sail'\n",
      " 'p-sn' 'icp3' 'a130' '2337' '\\x1f˙˙˙' 'lgl0' 'l\\x15' '@i\\uf8f5\\uf8f5'\n",
      " 'li\\x90o' '4lio' 'lp' 'li?' '\\x04ion' 'pbso' 'a138' 'li-h' '6ion' '3500'\n",
      " 'h00j' 'li\\x10' 'sams' '\\x03ip' '8' '#TAB#' 'l\\x06&#TAB#' 'liÿÿ' 'lÿÿÿ']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[nan nan nan ... nan nan nan].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4655262ddfbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Remove the rows, where the value count is less than 1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCensus_InternalBatteryType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Census_InternalBatteryType'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Census_InternalBatteryType'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCensus_InternalBatteryType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/impute.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \"\"\"\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/impute.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    195\u001b[0m                                  \"\".format(self.strategy, X.dtype.kind))\n\u001b[1;32m    196\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0m_check_inputs_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/impute.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             X = check_array(X, accept_sparse='csc', dtype=dtype,\n\u001b[0;32m--> 190\u001b[0;31m                             force_all_finite=force_all_finite, copy=self.copy)\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"could not convert\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[nan nan nan ... nan nan nan].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Remove the rows, where the value count is less than 1000\n",
    "print(df.Census_InternalBatteryType.unique())\n",
    "df['Census_InternalBatteryType'] = imputer.fit_transform(df['Census_InternalBatteryType'])\n",
    "print(df.Census_InternalBatteryType.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of nulls\n",
    "print(type(df.isnull().sum()/df.shape[0]))\n",
    "plt.figure()\n",
    "# (df.isnull().sum()/df.shape[0]).plot.hist()\n",
    "print((df.isnull().sum()/df.shape[0]).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows, where the value count is less than 1000\n",
    "print(df.Census_InternalBatteryType.value_counts())\n",
    "# vc = df.Census_InternalBatteryType.value_counts()\n",
    "# u  = [i not in set(vc[vc<1000].index) for i in df['Census_InternalBatteryType']]\n",
    "# df = df[u]\n",
    "print(df.Census_InternalBatteryType.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.SmartScreen == '&#x01;'].index, inplace=True)\n",
    "df.drop(df[df.SmartScreen == '&#x02;'].index, inplace=True)\n",
    "df.drop(df[df.SmartScreen == '&#x03;'].index, inplace=True)\n",
    "df.drop(df[df.SmartScreen == '0'].index, inplace=True)\n",
    "df.drop(df[df.SmartScreen == '00000000'].index, inplace=True)\n",
    "df.drop(df[df.SmartScreen == 'Enabled'].index, inplace=True)\n",
    "print(df['SmartScreen'].unique())\n",
    "df.SmartScreen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['SmartScreen'].unique())\n",
    "df.SmartScreen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of nulls\n",
    "print(type(df.isnull().sum()/df.shape[0]))\n",
    "plt.figure()\n",
    "# (df.isnull().sum()/df.shape[0]).plot.hist()\n",
    "print((df.isnull().sum()/df.shape[0]).sort_values(ascending=False))\n",
    "(df.isnull().sum()/df.shape[0]).sort_values().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in drop_list:\n",
    "    print('Dropping: ' + col)\n",
    "    df = df.drop(f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with only 1 unique value\n",
    "# Should do in the end also.\n",
    "# TODO\n",
    "# df.dropna(thresh=2)\n",
    "for col in df:\n",
    "    if(len(df.loc[:,col].unique()) == 1):\n",
    "        print('Dropping: ' + col)\n",
    "        drop_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "# start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Census_OSVersion_0'] = df['Census_OSVersion'].apply(break_and_get_part, position=0)\n",
    "df['Census_OSVersion_1'] = df['Census_OSVersion'].apply(break_and_get_part, position=1)\n",
    "df['Census_OSVersion_2'] = df['Census_OSVersion'].apply(break_and_get_part, position=2)\n",
    "df['Census_OSVersion_3'] = df['Census_OSVersion'].apply(break_and_get_part, position=3)\n",
    "\n",
    "drop_list.append('Census_OSVersion')\n",
    "\n",
    "print(df['Census_OSVersion_0'].unique())\n",
    "print(df['Census_OSVersion_1'].unique())\n",
    "print(df['Census_OSVersion_2'].unique())\n",
    "print(df['Census_OSVersion_3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.SmartScreen == 'off', 'SmartScreen'] = \"Off\"\n",
    "df.loc[df.SmartScreen == 'on', 'SmartScreen'] = \"On\"\n",
    "df.loc[df.SmartScreen == 'OFF', 'SmartScreen'] = \"Off\"\n",
    "df.loc[df.SmartScreen == 'requireAdmin', 'SmartScreen'] = \"RequireAdmin\"\n",
    "df.loc[df.SmartScreen == 'Promt', 'SmartScreen'] = \"Prompt\"\n",
    "df.loc[df.SmartScreen == 'prompt', 'SmartScreen'] = \"Prompt\"\n",
    "df.loc[df.SmartScreen == 'warn', 'SmartScreen'] = \"Warn\"\n",
    "df.loc[df.SmartScreen == 'requireadmin', 'SmartScreen'] = \"RequireAdmin\"\n",
    "print(df['SmartScreen'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['OsBuildLab'].dtype)\n",
    "# print(df['OsBuildLab'].unique())\n",
    "df['OsBuildLab_0'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=0)\n",
    "df['OsBuildLab_1'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=1)\n",
    "df['OsBuildLab_2'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=2)\n",
    "df['OsBuildLab_3'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=3)\n",
    "df['OsBuildLab_4'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=4)\n",
    "df['OsBuildLab_5'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=5)\n",
    "drop_list.append('OsBuildLab')\n",
    "print(df['OsBuildLab_0'].unique())\n",
    "print(df['OsBuildLab_1'].unique())\n",
    "print(df['OsBuildLab_2'].unique())\n",
    "print(df['OsBuildLab_3'].unique())\n",
    "print(df['OsBuildLab_4'].unique())\n",
    "print(df['OsBuildLab_5'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def break_and_get_part_osbuildlab(value, position):\n",
    "    if position < 4:\n",
    "        try:\n",
    "            return value.split(\".\")[position]\n",
    "        except:\n",
    "            return math.nan\n",
    "    elif position == 4:\n",
    "        try:\n",
    "            return value.split(\".\")[4].split('-')[0]\n",
    "        except:\n",
    "            return math.nan\n",
    "    elif position == 5:\n",
    "        try:\n",
    "            return value.split(\".\")[4].split('-')[1]\n",
    "        except:\n",
    "            return math.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OsVer_0'] = df['OsVer'].apply(break_and_get_part, position=0)\n",
    "df['OsVer_1'] = df['OsVer'].apply(break_and_get_part, position=1)\n",
    "df['OsVer_2'] = df['OsVer'].apply(break_and_get_part, position=2)\n",
    "df['OsVer_3'] = df['OsVer'].apply(break_and_get_part, position=3)\n",
    "drop_list.append('OsVer')\n",
    "print(df['OsVer_0'].unique())\n",
    "print(df['OsVer_1'].unique())\n",
    "print(df['OsVer_2'].unique())\n",
    "print(df['OsVer_3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['EngineVersion_0'].unique())\n",
    "print(df['EngineVersion_1'].unique())\n",
    "print(df['EngineVersion_2'].unique())\n",
    "print(df['EngineVersion_3'].unique())\n",
    "print(df['AppVersion_0'].unique())\n",
    "print(df['AppVersion_1'].unique())\n",
    "print(df['AppVersion_2'].unique())\n",
    "print(df['AppVersion_3'].unique())\n",
    "print(df['AvSigVersion_0'].unique())\n",
    "print(df['AvSigVersion_1'].unique())\n",
    "print(df['AvSigVersion_2'].unique())\n",
    "print(df['AvSigVersion_3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EngineVersion_0'] = df['EngineVersion'].apply(break_and_get_part, position=0)\n",
    "df['EngineVersion_1'] = df['EngineVersion'].apply(break_and_get_part, position=1)\n",
    "df['EngineVersion_2'] = df['EngineVersion'].apply(break_and_get_part, position=2)\n",
    "df['EngineVersion_3'] = df['EngineVersion'].apply(break_and_get_part, position=3)\n",
    "\n",
    "df['AppVersion_0'] = df['AppVersion'].apply(break_and_get_part, position=0)\n",
    "df['AppVersion_1'] = df['AppVersion'].apply(break_and_get_part, position=1)\n",
    "df['AppVersion_2'] = df['AppVersion'].apply(break_and_get_part, position=2)\n",
    "df['AppVersion_3'] = df['AppVersion'].apply(break_and_get_part, position=3)\n",
    "\n",
    "df['AvSigVersion_0'] = df['AvSigVersion'].apply(break_and_get_part, position=0)\n",
    "df['AvSigVersion_1'] = df['AvSigVersion'].apply(break_and_get_part, position=1)\n",
    "df['AvSigVersion_2'] = df['AvSigVersion'].apply(break_and_get_part, position=2)\n",
    "df['AvSigVersion_3'] = df['AvSigVersion'].apply(break_and_get_part, position=3)\n",
    "\n",
    "drop_list.append('EngineVersion')\n",
    "drop_list.append('AppVersion')\n",
    "drop_list.append('AvSigVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_and_get_part(value, position):\n",
    "    return value.split(\".\")[position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now analyze one column at a time\n",
    "start_cnt = 0\n",
    "show_cnt = 5\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "    print(y, df[y].dtype)\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with only 1 unique value\n",
    "# Should do in the end also.\n",
    "# TODO\n",
    "# df.dropna(thresh=2)\n",
    "for col in df:\n",
    "    if(len(df.loc[:,col].unique()) == 1):\n",
    "        print('Dropping: ' + col)\n",
    "        drop_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop MachineIdentifier\n",
    "drop_list.append('MachineIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = []\n",
    "\n",
    "import operator \n",
    "# Find all the NaN\n",
    "# See what percentage of each column is NaN\n",
    "x_pct = {}\n",
    "length = len(df)\n",
    "for y in df.columns:\n",
    "    if df[y].isnull().sum() > 0:\n",
    "        x_cnt = df[y].isnull().sum()\n",
    "        x_pct[y] = 100.0*x_cnt/length\n",
    "        \n",
    "x_pct_list = sorted(x_pct.items(), key=operator.itemgetter(1), reverse=True)\n",
    "      \n",
    "# Print the features, where more than 80% of the data is NaN    \n",
    "for f, val in x_pct_list:\n",
    "    if val > 80:\n",
    "        print(f, val)\n",
    "        drop_list.append(f)\n",
    "        print('Dropping: ' + f)\n",
    "        print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Percentage of nulls\n",
    "print(type(df.isnull().sum()/df.shape[0]))\n",
    "plt.figure()\n",
    "# (df.isnull().sum()/df.shape[0]).plot.hist()\n",
    "print((df.isnull().sum()/df.shape[0]).sort_values())\n",
    "(df.isnull().sum()/df.shape[0]).sort_values().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete columns, where all the entries are 0.\n",
    "df = df.loc[:, (df != 0).any(axis=0)]\n",
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/train.csv'\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import Imputer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
