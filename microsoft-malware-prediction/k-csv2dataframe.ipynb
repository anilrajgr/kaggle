{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
    "    start = time() # Get start time\n",
    "    learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set,\n",
    "    #       then get predictions on the first 300 training samples\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train)\n",
    "    end = time() # Get end time\n",
    "       \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples\n",
    "    results['acc_train'] = accuracy_score(y_train, learner.predict(X_train))\n",
    "        \n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['acc_test'] = accuracy_score(y_test, learner.predict(X_test))\n",
    "    \n",
    "    # TODO: Compute F-score on the the first 300 training samples\n",
    "    results['f_train'] = fbeta_score(y_train, learner.predict(X_train), beta=0.5)\n",
    "        \n",
    "    # TODO: Compute F-score on the test set\n",
    "    results['f_test'] = fbeta_score(y_test, learner.predict(X_test), beta=0.5)\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the features and loan_status data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, loan_status, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ProductName', 'Platform', 'Processor', 'OsPlatformSubRelease',\n",
      "       'SkuEdition', 'SmartScreen', 'Census_MDC2FormFactor',\n",
      "       'Census_DeviceFamily', 'Census_PrimaryDiskTypeName',\n",
      "       'Census_ChassisTypeName', 'Census_PowerPlatformRoleName',\n",
      "       'Census_InternalBatteryType', 'Census_OSArchitecture',\n",
      "       'Census_OSBranch', 'Census_OSEdition', 'Census_OSSkuName',\n",
      "       'Census_OSInstallTypeName', 'Census_OSWUAutoUpdateOptionsName',\n",
      "       'Census_GenuineStateName', 'Census_ActivationChannel',\n",
      "       'Census_FlightRing', 'EngineVersion_2', 'EngineVersion_3',\n",
      "       'AppVersion_1', 'AppVersion_2', 'AppVersion_3', 'AvSigVersion_0',\n",
      "       'AvSigVersion_1', 'AvSigVersion_2', 'OsVer_0', 'OsVer_1', 'OsVer_2',\n",
      "       'OsVer_3', 'OsBuildLab_0', 'OsBuildLab_1', 'OsBuildLab_2',\n",
      "       'OsBuildLab_3', 'OsBuildLab_4', 'OsBuildLab_5', 'Census_OSVersion_0',\n",
      "       'Census_OSVersion_1', 'Census_OSVersion_2', 'Census_OSVersion_3'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "MemoryError()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getbool_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1495\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   2781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2782\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4435\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   4423\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4424\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4425\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   4432\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4433\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4097\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4098\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4099\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4104\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   5068\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 5069\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   5070\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   5091\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5092\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5093\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c35f6be00a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3692\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3693\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3694\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3108\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3161\u001b[0m             \u001b[0mslicer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3163\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1866\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1868\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1869\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getbool_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: MemoryError()"
     ]
    }
   ],
   "source": [
    "# Categorical features \n",
    "cat_features = features.select_dtypes(include=['object']).columns\n",
    "print(cat_features)\n",
    "\n",
    "for y in cat_features:\n",
    "    features = features.join(pd.get_dummies(features[y], prefix=y))\n",
    "    features.drop(y, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in features and target label\n",
    "labels = df['HasDetections']\n",
    "features = df.drop('HasDetections', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('HasDetections').size().plot(kind='bar', title='HasDetections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of nulls\n",
    "print(type(df.isnull().sum()/df.shape[0]))\n",
    "plt.figure()\n",
    "# (df.isnull().sum()/df.shape[0]).plot.hist()\n",
    "print((df.isnull().sum()/df.shape[0]).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows, where the value count is less than 1000\n",
    "print(df.Census_InternalBatteryType.value_counts())\n",
    "# vc = df.Census_InternalBatteryType.value_counts()\n",
    "# u  = [i not in set(vc[vc<1000].index) for i in df['Census_InternalBatteryType']]\n",
    "# df = df[u]\n",
    "print(df.Census_InternalBatteryType.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.SmartScreen == '&#x01;'].index, inplace=True)\n",
    "df.drop(df[df.SmartScreen == '&#x02;'].index, inplace=True)\n",
    "df.drop(df[df.SmartScreen == '&#x03;'].index, inplace=True)\n",
    "df.drop(df[df.SmartScreen == '0'].index, inplace=True)\n",
    "df.drop(df[df.SmartScreen == '00000000'].index, inplace=True)\n",
    "df.drop(df[df.SmartScreen == 'Enabled'].index, inplace=True)\n",
    "print(df['SmartScreen'].unique())\n",
    "df.SmartScreen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['SmartScreen'].unique())\n",
    "df.SmartScreen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of nulls\n",
    "print(type(df.isnull().sum()/df.shape[0]))\n",
    "plt.figure()\n",
    "# (df.isnull().sum()/df.shape[0]).plot.hist()\n",
    "print((df.isnull().sum()/df.shape[0]).sort_values(ascending=False))\n",
    "(df.isnull().sum()/df.shape[0]).sort_values().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in drop_list:\n",
    "    print('Dropping: ' + col)\n",
    "    df = df.drop(f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with only 1 unique value\n",
    "# Should do in the end also.\n",
    "# TODO\n",
    "# df.dropna(thresh=2)\n",
    "for col in df:\n",
    "    if(len(df.loc[:,col].unique()) == 1):\n",
    "        print('Dropping: ' + col)\n",
    "        drop_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "# start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "# print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Census_OSVersion_0'] = df['Census_OSVersion'].apply(break_and_get_part, position=0)\n",
    "df['Census_OSVersion_1'] = df['Census_OSVersion'].apply(break_and_get_part, position=1)\n",
    "df['Census_OSVersion_2'] = df['Census_OSVersion'].apply(break_and_get_part, position=2)\n",
    "df['Census_OSVersion_3'] = df['Census_OSVersion'].apply(break_and_get_part, position=3)\n",
    "\n",
    "drop_list.append('Census_OSVersion')\n",
    "\n",
    "print(df['Census_OSVersion_0'].unique())\n",
    "print(df['Census_OSVersion_1'].unique())\n",
    "print(df['Census_OSVersion_2'].unique())\n",
    "print(df['Census_OSVersion_3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.SmartScreen == 'off', 'SmartScreen'] = \"Off\"\n",
    "df.loc[df.SmartScreen == 'on', 'SmartScreen'] = \"On\"\n",
    "df.loc[df.SmartScreen == 'OFF', 'SmartScreen'] = \"Off\"\n",
    "df.loc[df.SmartScreen == 'requireAdmin', 'SmartScreen'] = \"RequireAdmin\"\n",
    "df.loc[df.SmartScreen == 'Promt', 'SmartScreen'] = \"Prompt\"\n",
    "df.loc[df.SmartScreen == 'prompt', 'SmartScreen'] = \"Prompt\"\n",
    "df.loc[df.SmartScreen == 'warn', 'SmartScreen'] = \"Warn\"\n",
    "df.loc[df.SmartScreen == 'requireadmin', 'SmartScreen'] = \"RequireAdmin\"\n",
    "print(df['SmartScreen'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['OsBuildLab'].dtype)\n",
    "# print(df['OsBuildLab'].unique())\n",
    "df['OsBuildLab_0'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=0)\n",
    "df['OsBuildLab_1'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=1)\n",
    "df['OsBuildLab_2'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=2)\n",
    "df['OsBuildLab_3'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=3)\n",
    "df['OsBuildLab_4'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=4)\n",
    "df['OsBuildLab_5'] = df['OsBuildLab'].apply(break_and_get_part_osbuildlab, position=5)\n",
    "drop_list.append('OsBuildLab')\n",
    "print(df['OsBuildLab_0'].unique())\n",
    "print(df['OsBuildLab_1'].unique())\n",
    "print(df['OsBuildLab_2'].unique())\n",
    "print(df['OsBuildLab_3'].unique())\n",
    "print(df['OsBuildLab_4'].unique())\n",
    "print(df['OsBuildLab_5'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def break_and_get_part_osbuildlab(value, position):\n",
    "    if position < 4:\n",
    "        try:\n",
    "            return value.split(\".\")[position]\n",
    "        except:\n",
    "            return math.nan\n",
    "    elif position == 4:\n",
    "        try:\n",
    "            return value.split(\".\")[4].split('-')[0]\n",
    "        except:\n",
    "            return math.nan\n",
    "    elif position == 5:\n",
    "        try:\n",
    "            return value.split(\".\")[4].split('-')[1]\n",
    "        except:\n",
    "            return math.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OsVer_0'] = df['OsVer'].apply(break_and_get_part, position=0)\n",
    "df['OsVer_1'] = df['OsVer'].apply(break_and_get_part, position=1)\n",
    "df['OsVer_2'] = df['OsVer'].apply(break_and_get_part, position=2)\n",
    "df['OsVer_3'] = df['OsVer'].apply(break_and_get_part, position=3)\n",
    "drop_list.append('OsVer')\n",
    "print(df['OsVer_0'].unique())\n",
    "print(df['OsVer_1'].unique())\n",
    "print(df['OsVer_2'].unique())\n",
    "print(df['OsVer_3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now analyze the next 5 features\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "  print(y, df[y].dtype)\n",
    "  print(df[y].unique())\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['EngineVersion_0'].unique())\n",
    "print(df['EngineVersion_1'].unique())\n",
    "print(df['EngineVersion_2'].unique())\n",
    "print(df['EngineVersion_3'].unique())\n",
    "print(df['AppVersion_0'].unique())\n",
    "print(df['AppVersion_1'].unique())\n",
    "print(df['AppVersion_2'].unique())\n",
    "print(df['AppVersion_3'].unique())\n",
    "print(df['AvSigVersion_0'].unique())\n",
    "print(df['AvSigVersion_1'].unique())\n",
    "print(df['AvSigVersion_2'].unique())\n",
    "print(df['AvSigVersion_3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EngineVersion_0'] = df['EngineVersion'].apply(break_and_get_part, position=0)\n",
    "df['EngineVersion_1'] = df['EngineVersion'].apply(break_and_get_part, position=1)\n",
    "df['EngineVersion_2'] = df['EngineVersion'].apply(break_and_get_part, position=2)\n",
    "df['EngineVersion_3'] = df['EngineVersion'].apply(break_and_get_part, position=3)\n",
    "\n",
    "df['AppVersion_0'] = df['AppVersion'].apply(break_and_get_part, position=0)\n",
    "df['AppVersion_1'] = df['AppVersion'].apply(break_and_get_part, position=1)\n",
    "df['AppVersion_2'] = df['AppVersion'].apply(break_and_get_part, position=2)\n",
    "df['AppVersion_3'] = df['AppVersion'].apply(break_and_get_part, position=3)\n",
    "\n",
    "df['AvSigVersion_0'] = df['AvSigVersion'].apply(break_and_get_part, position=0)\n",
    "df['AvSigVersion_1'] = df['AvSigVersion'].apply(break_and_get_part, position=1)\n",
    "df['AvSigVersion_2'] = df['AvSigVersion'].apply(break_and_get_part, position=2)\n",
    "df['AvSigVersion_3'] = df['AvSigVersion'].apply(break_and_get_part, position=3)\n",
    "\n",
    "drop_list.append('EngineVersion')\n",
    "drop_list.append('AppVersion')\n",
    "drop_list.append('AvSigVersion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_and_get_part(value, position):\n",
    "    return value.split(\".\")[position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now analyze one column at a time\n",
    "start_cnt = 0\n",
    "show_cnt = 5\n",
    "print(df.iloc[:5,start_cnt:start_cnt+show_cnt])\n",
    "for y in df.columns[start_cnt:start_cnt+show_cnt]:\n",
    "    print(y, df[y].dtype)\n",
    "start_cnt += show_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blindly replace all nan with 0.\n",
    "# This has to be change later.\n",
    "df = df.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with only 1 unique value\n",
    "# Should do in the end also.\n",
    "# TODO\n",
    "# df.dropna(thresh=2)\n",
    "for col in df:\n",
    "    if(len(df.loc[:,col].unique()) == 1):\n",
    "        print('Dropping: ' + col)\n",
    "        drop_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop MachineIdentifier\n",
    "drop_list.append('MachineIdentifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = []\n",
    "\n",
    "import operator \n",
    "# Find all the NaN\n",
    "# See what percentage of each column is NaN\n",
    "x_pct = {}\n",
    "length = len(df)\n",
    "for y in df.columns:\n",
    "    if df[y].isnull().sum() > 0:\n",
    "        x_cnt = df[y].isnull().sum()\n",
    "        x_pct[y] = 100.0*x_cnt/length\n",
    "        \n",
    "x_pct_list = sorted(x_pct.items(), key=operator.itemgetter(1), reverse=True)\n",
    "      \n",
    "# Print the features, where more than 80% of the data is NaN    \n",
    "for f, val in x_pct_list:\n",
    "    if val > 80:\n",
    "        print(f, val)\n",
    "        drop_list.append(f)\n",
    "        print('Dropping: ' + f)\n",
    "        print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Percentage of nulls\n",
    "print(type(df.isnull().sum()/df.shape[0]))\n",
    "plt.figure()\n",
    "# (df.isnull().sum()/df.shape[0]).plot.hist()\n",
    "print((df.isnull().sum()/df.shape[0]).sort_values())\n",
    "(df.isnull().sum()/df.shape[0]).sort_values().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete columns, where all the entries are 0.\n",
    "df = df.loc[:, (df != 0).any(axis=0)]\n",
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/train.csv'\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import Imputer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
